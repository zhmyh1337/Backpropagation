{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение алгоритма обратного распространения ошибки для решения задач регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def function(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "    def derivative(self, x):\n",
    "        return x > 0\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def function(self, x):\n",
    "        return x\n",
    "\n",
    "    def derivative(self, x):\n",
    "        return 1\n",
    "\n",
    "\n",
    "class MSE:\n",
    "    def function(self, y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "    def derivative(self, y_pred, y_true):\n",
    "        return 2 * (y_pred - y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, in_neurons_count, out_neurons_count, activation):\n",
    "        self.in_neurons_count = in_neurons_count\n",
    "        self.out_neurons_count = out_neurons_count\n",
    "        self.activation = activation\n",
    "\n",
    "        self.weights = np.random.normal(size=(in_neurons_count, out_neurons_count)) / np.sqrt(in_neurons_count)\n",
    "        self.biases = np.zeros(out_neurons_count)\n",
    "\n",
    "        self.weights_grad = np.zeros((in_neurons_count, out_neurons_count))\n",
    "        self.biases_grad = np.zeros(out_neurons_count)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.unactivated_outputs = inputs @ self.weights + self.biases\n",
    "        self.activated_outputs = self.activation.function(self.unactivated_outputs)\n",
    "        return self.activated_outputs\n",
    "\n",
    "    def calculate_dQdu_as_output_layer(self, y_true, cost):\n",
    "        dQda = cost.derivative(self.activated_outputs, y_true) # partial derivative of the cost with respect to the activated output\n",
    "        self.dQdu = dQda * self.activation.derivative(self.unactivated_outputs) # partial derivative of the cost with respect to the unactivated output\n",
    "\n",
    "    def calculate_dQdu_as_hidden_layer(self, next_layer):\n",
    "        dQda = next_layer.weights @ next_layer.dQdu # partial derivative of the cost with respect to the activated output\n",
    "        self.dQdu = dQda * self.activation.derivative(self.unactivated_outputs) # partial derivative of the cost with respect to the unactivated output\n",
    "\n",
    "    def update_gradients(self):\n",
    "        self.weights_grad += self.inputs.reshape((-1, 1)) @ self.dQdu.reshape((1, -1))\n",
    "        self.biases_grad += self.dQdu\n",
    "\n",
    "    def apply_and_reset_gradients(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.weights_grad\n",
    "        self.biases -= learning_rate * self.biases_grad\n",
    "        self.weights_grad = np.zeros(self.weights_grad.shape)\n",
    "        self.biases_grad = np.zeros(self.biases_grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.forward(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def backpropagation(self, y_true, cost):\n",
    "        output_layer = self.layers[-1]\n",
    "        output_layer.calculate_dQdu_as_output_layer(y_true, cost)\n",
    "        output_layer.update_gradients()\n",
    "        next_layer = output_layer\n",
    "\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            layer.calculate_dQdu_as_hidden_layer(next_layer)\n",
    "            layer.update_gradients()\n",
    "            next_layer = layer\n",
    "\n",
    "    def train_batch(self, batch_x, batch_y, cost, learning_rate):\n",
    "        for x, y in zip(batch_x, batch_y):\n",
    "            self.forward(x)\n",
    "            self.backpropagation(y, cost)\n",
    "        for layer in self.layers:\n",
    "            layer.apply_and_reset_gradients(learning_rate / batch_x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0  2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905 -25.01202   \n",
       "1  2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   8.76630   \n",
       "2  2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940  -3.27872   \n",
       "3  2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   5.05097   \n",
       "4  2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409 -12.48207   \n",
       "\n",
       "         8         9   ...        81         82        83        84        85  \\\n",
       "0 -12.23257   7.83089  ...  13.01620  -54.40548  58.99367  15.37344   1.11144   \n",
       "1  -0.92019  18.76548  ...   5.66812  -19.68073  33.04964  42.87836  -9.90378   \n",
       "2  -2.35035  16.07017  ...   3.03800   26.05866 -50.92779  10.93792  -0.07568   \n",
       "3 -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705 -46.67617 -12.51516   \n",
       "4  -9.37636  12.63699  ...   9.92661  -55.95724  64.92712 -17.72522  -1.49237   \n",
       "\n",
       "         86         87        88         89        90  \n",
       "0 -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n",
       "1 -32.22788   70.49388  12.04941   58.43453  26.92061  \n",
       "2  43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n",
       "3  82.58061  -72.08993   9.90558  199.62971  18.85382  \n",
       "4  -7.50035   51.76631   7.88713   55.66926  28.74903  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"\"\"\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.txt.zip', header=None)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.iloc[:, 1:].values.astype('float32')\n",
    "y = df.iloc[:, 0:1].values.astype('float32')\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc_target = StandardScaler()\n",
    "\n",
    "train_size = 463715\n",
    "X_train = sc.fit_transform(X[:train_size, :])\n",
    "y_train = sc_target.fit_transform(y[:train_size])\n",
    "X_test = sc.transform(X[train_size:, :])\n",
    "y_test = y[train_size:]\n",
    "#\"\"\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "model = NN([\n",
    "    Layer(X_train.shape[1], 32, ReLU()),\n",
    "    Layer(32, 8, ReLU()),\n",
    "    Layer(8, 1, Linear())\n",
    "])\n",
    "\n",
    "learning_rate = 5e-3\n",
    "cost_func = MSE()\n",
    "\n",
    "batch_size = 32\n",
    "batches_count = int(np.ceil(X_train.shape[0] / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e76dd2245194ed1b951315846b993e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/14492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 12.664008045099035\n",
      "RMSE on test: 9.85827844248504\n",
      "RMSE on test: 9.352224778076339\n",
      "RMSE on test: 9.239214708773277\n",
      "RMSE on test: 9.1379865311595\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a90c863ef14758a38b0697f9511a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/14492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 9.121120902011464\n",
      "RMSE on test: 9.193855201672555\n",
      "RMSE on test: 9.105957313645762\n",
      "RMSE on test: 9.068807036595937\n",
      "RMSE on test: 9.020488546311297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3219b74ba31b48079e316ad1af1df06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/14492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 9.045160202109473\n",
      "RMSE on test: 9.118188079225346\n",
      "RMSE on test: 9.045328072754822\n",
      "RMSE on test: 9.01973606231758\n",
      "RMSE on test: 8.986081847865291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af7f97df88046abbda144bfec56df5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/14492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 9.00856045092611\n",
      "RMSE on test: 9.082702899936438\n",
      "RMSE on test: 9.015131949426548\n",
      "RMSE on test: 8.988978231941774\n",
      "RMSE on test: 8.9647322615182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for epoch in range(4):\n",
    "    for batch_index, batch_start_index in enumerate(tqdm(range(0, X_train.shape[0], batch_size), f'Epoch {epoch}')):\n",
    "        batch_x = X_train[batch_start_index:batch_start_index + batch_size, :]\n",
    "        batch_y = y_train[batch_start_index:batch_start_index + batch_size, :]\n",
    "        model.train_batch(batch_x, batch_y, cost_func, learning_rate)\n",
    "\n",
    "        if batch_index % int(np.ceil(batches_count / 5)) == 0:\n",
    "            print('RMSE on test:', mean_squared_error(y_test, sc_target.inverse_transform(model.forward(X_test)), squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Та же модель на PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch_model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "optimizer = torch.optim.SGD(torch_model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.functional.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3603a359ecb6464fa329957e5429f7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/14492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 11.350731\n",
      "RMSE on test: 9.691548\n",
      "RMSE on test: 9.280447\n",
      "RMSE on test: 9.156673\n",
      "RMSE on test: 9.075457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0b7917ae6542e581a42a8595db3c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/14492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 9.079317\n",
      "RMSE on test: 9.150316\n",
      "RMSE on test: 9.066064\n",
      "RMSE on test: 9.023626\n",
      "RMSE on test: 8.985299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d02fd464e0b47c3a91e0f53b1c777a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/14492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 9.015455\n",
      "RMSE on test: 9.079324\n",
      "RMSE on test: 9.010445\n",
      "RMSE on test: 8.997958\n",
      "RMSE on test: 8.955013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e270f0a4b3447f8816e07988644afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/14492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test: 8.982645\n",
      "RMSE on test: 9.044628\n",
      "RMSE on test: 8.986022\n",
      "RMSE on test: 8.968505\n",
      "RMSE on test: 8.935136\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    for batch_index, batch_start_index in enumerate(tqdm(range(0, X_train.shape[0], batch_size), f'Epoch {epoch}')):\n",
    "        batch_x = torch.Tensor(X_train[batch_start_index:batch_start_index + batch_size, :])\n",
    "        batch_y = torch.Tensor(y_train[batch_start_index:batch_start_index + batch_size, :])\n",
    "        y_pred = torch_model(batch_x)\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_index % int(np.ceil(batches_count / 5)) == 0:\n",
    "            print('RMSE on test:', mean_squared_error(y_test, sc_target.inverse_transform(torch_model(torch.Tensor(X_test)).detach().numpy()), squared=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
